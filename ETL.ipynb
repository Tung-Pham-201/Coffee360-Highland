{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53dce5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3e757b",
   "metadata": {},
   "source": [
    "## Extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282b392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4j/zzpj65z16_v0szts7v839b300000gn/T/ipykernel_10130/3529534785.py:3: DtypeWarning: Columns (4,7,8,10,11,12,16,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_BH = pd.read_csv('Data/Brandhealth.csv', sep=';')\n"
     ]
    }
   ],
   "source": [
    "df_BI = pd.read_csv('Data/Brand_Image.csv', sep=';') \n",
    "df_smt = pd.read_csv('Data/2017Segmentation3685case.csv', sep=';')\n",
    "df_BH = pd.read_csv('Data/Brandhealth.csv', sep=';')\n",
    "df_cp = pd.read_csv('Data/Companion.csv', sep=';')\n",
    "df_count = pd.read_csv('Data/Competitor database_xlnm#_FilterDatabase.csv', sep=';')\n",
    "df_dow= pd.read_csv('Data/Dayofweek.csv', sep=';')\n",
    "df_dp = pd.read_csv('Data/Daypart.csv', sep=';')\n",
    "df_ns = pd.read_csv('Data/NeedstateDayDaypart.csv', sep=';')\n",
    "df_sa = pd.read_csv('Data/SA#var.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd6f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BI.drop_duplicates(inplace=True)\n",
    "df_smt.drop_duplicates(inplace=True)\n",
    "df_BH.drop_duplicates(inplace=True)\n",
    "df_cp.drop_duplicates(inplace=True)\n",
    "df_count.drop_duplicates(inplace=True)\n",
    "df_dow.drop_duplicates(inplace=True)\n",
    "df_dp.drop_duplicates(inplace=True)\n",
    "df_ns.drop_duplicates(inplace=True)\n",
    "df_sa.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00644a",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e35c743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DayofWeek_ID  Dayofweek Weekday#end\n",
      "0             2     Monday     Weekday\n",
      "1             3    Tuesday     Weekday\n",
      "2             4  Wednesday     Weekday\n",
      "3             5   Thursday     Weekday\n",
      "4             6     Friday     Weekday\n",
      "5             7   Saturday     Weekend\n",
      "6             8     Sunday     Weekend\n"
     ]
    }
   ],
   "source": [
    "##1 Dim_Dayofweek\n",
    "dow = [(2, 'Monday', 'Weekday'), \n",
    "       (3, 'Tuesday', 'Weekday'), \n",
    "       (4, 'Wednesday', 'Weekday'), \n",
    "       (5, 'Thursday', 'Weekday'), \n",
    "       (6, 'Friday', 'Weekday'), \n",
    "       (7, 'Saturday', 'Weekend'), \n",
    "       (8, 'Sunday', 'Weekend')]\n",
    "df_dim_dow = pd.DataFrame(dow, columns=['DayofWeek_ID', 'Dayofweek', 'Weekday#end'])\n",
    "print(df_dim_dow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a017fa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Daypart  Daypart_ID\n",
      "0   5 PM - before 9 PM           1\n",
      "1  9 AM - before 11 AM           2\n",
      "2        9 PM or later           3\n",
      "3   2 PM - before 5 PM           4\n",
      "4  11 AM - before 2 PM           5\n",
      "5          Before 9 AM           6\n"
     ]
    }
   ],
   "source": [
    "##2 Dim_Daypart\n",
    "df_dim_daypart = df_dp[['Daypart']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_dim_daypart['Daypart_ID'] = range(1, len(df_dim_daypart) + 1)\n",
    "print(df_dim_daypart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a2f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year\n",
      "0  2017\n",
      "1  2018\n",
      "2  2019\n"
     ]
    }
   ],
   "source": [
    "##3 Dim_Year\n",
    "df_dim_year = pd.DataFrame({'Year': [2017, 2018, 2019]})\n",
    "print(df_dim_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff1ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              City  City_ID\n",
      "0          Cần Thơ        1\n",
      "1           Hà Nội        2\n",
      "2      Hồ Chí Minh        3\n",
      "3          Đà Nẵng        4\n",
      "4        Hải Phòng        5\n",
      "5        Nha Trang        6\n",
      "6          Lào Cai        7\n",
      "7        Quảng Nam        8\n",
      "8       Quảng Ninh        9\n",
      "9            Seoul       10\n",
      "10        Hưng Yên       11\n",
      "11        Nam Định       12\n",
      "12       Thái Bình       13\n",
      "13        Đồng Nai       14\n",
      "14        Vũng Tàu       15\n",
      "15         Đắk Lắk       16\n",
      "16        Gyeonggi       17\n",
      "17        Lạng Sơn       18\n",
      "18     Thái Nguyên       19\n",
      "19  Thừa Thiên Huế       20\n",
      "20       Bình Định       21\n",
      "21         Long An       22\n",
      "22         Phú Thọ       23\n",
      "23      Tiền Giang       24\n",
      "24      Bình Dương       25\n",
      "25       Thanh Hóa       26\n",
      "26          Hà Nam       27\n",
      "27        Bắc Ninh       28\n",
      "28         Nghệ An       29\n"
     ]
    }
   ],
   "source": [
    "##4 Dim_City\n",
    "cities_from_sa = df_sa[['City']].dropna()\n",
    "cities_from_store = df_count[['City']].dropna()\n",
    "df_dim_city = pd.concat([cities_from_sa, cities_from_store]).drop_duplicates().reset_index(drop=True)\n",
    "df_dim_city['City_ID'] = range(1, len(df_dim_city) + 1)\n",
    "print(df_dim_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3c979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>City</th>\n",
       "      <th>Group_size</th>\n",
       "      <th>Age</th>\n",
       "      <th>MPI#Mean</th>\n",
       "      <th>TOM</th>\n",
       "      <th>BUMO</th>\n",
       "      <th>BUMO_Previous</th>\n",
       "      <th>MostFavourite</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MPI#detail</th>\n",
       "      <th>Age#group</th>\n",
       "      <th>Age#Group#2</th>\n",
       "      <th>MPI</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Occupation#group</th>\n",
       "      <th>Year</th>\n",
       "      <th>Col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>348226</td>\n",
       "      <td>Cần Thơ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5499.0</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>Female</td>\n",
       "      <td>From 4.5 millions to 6.49 millions VND</td>\n",
       "      <td>20 - 29</td>\n",
       "      <td>25 - 29 y.o.</td>\n",
       "      <td>VND 4.5m - VND 8.9m</td>\n",
       "      <td>Unskilled Labor (worker, landry person, driver...</td>\n",
       "      <td>Blue Collar</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>358485</td>\n",
       "      <td>Hà Nội</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5499.0</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>Male</td>\n",
       "      <td>From 4.5 millions to 6.49 millions VND</td>\n",
       "      <td>20 - 29</td>\n",
       "      <td>25 - 29 y.o.</td>\n",
       "      <td>VND 4.5m - VND 8.9m</td>\n",
       "      <td>Unskilled Labor (worker, landry person, driver...</td>\n",
       "      <td>Blue Collar</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360729</td>\n",
       "      <td>Cần Thơ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5499.0</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>Female</td>\n",
       "      <td>From 4.5 millions to 6.49 millions VND</td>\n",
       "      <td>20 - 29</td>\n",
       "      <td>25 - 29 y.o.</td>\n",
       "      <td>VND 4.5m - VND 8.9m</td>\n",
       "      <td>Unskilled Labor (worker, landry person, driver...</td>\n",
       "      <td>Blue Collar</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360737</td>\n",
       "      <td>Cần Thơ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5499.0</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>Male</td>\n",
       "      <td>From 4.5 millions to 6.49 millions VND</td>\n",
       "      <td>20 - 29</td>\n",
       "      <td>20 - 24 y.o.</td>\n",
       "      <td>VND 4.5m - VND 8.9m</td>\n",
       "      <td>Skilled Labor (tailor, machinist, carpenter, e...</td>\n",
       "      <td>Blue Collar</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>361753</td>\n",
       "      <td>Cần Thơ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5499.0</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other 1</td>\n",
       "      <td>Male</td>\n",
       "      <td>From 4.5 millions to 6.49 millions VND</td>\n",
       "      <td>20 - 29</td>\n",
       "      <td>25 - 29 y.o.</td>\n",
       "      <td>VND 4.5m - VND 8.9m</td>\n",
       "      <td>Semi-skilled labor (salesperson, waiter, photo...</td>\n",
       "      <td>Blue Collar</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID     City  Group_size   Age  MPI#Mean      TOM     BUMO  \\\n",
       "0  348226  Cần Thơ         3.0  29.0    5499.0  Other 1  Other 1   \n",
       "1  358485   Hà Nội         3.0  25.0    5499.0  Other 1  Other 1   \n",
       "2  360729  Cần Thơ         3.0  25.0    5499.0  Other 1  Other 1   \n",
       "3  360737  Cần Thơ         3.0  24.0    5499.0  Other 1  Other 1   \n",
       "4  361753  Cần Thơ         3.0  26.0    5499.0  Other 1  Other 1   \n",
       "\n",
       "  BUMO_Previous MostFavourite  Gender                              MPI#detail  \\\n",
       "0           NaN       Other 1  Female  From 4.5 millions to 6.49 millions VND   \n",
       "1           NaN       Other 1    Male  From 4.5 millions to 6.49 millions VND   \n",
       "2           NaN       Other 1  Female  From 4.5 millions to 6.49 millions VND   \n",
       "3           NaN       Other 1    Male  From 4.5 millions to 6.49 millions VND   \n",
       "4           NaN       Other 1    Male  From 4.5 millions to 6.49 millions VND   \n",
       "\n",
       "  Age#group   Age#Group#2                  MPI  \\\n",
       "0   20 - 29  25 - 29 y.o.  VND 4.5m - VND 8.9m   \n",
       "1   20 - 29  25 - 29 y.o.  VND 4.5m - VND 8.9m   \n",
       "2   20 - 29  25 - 29 y.o.  VND 4.5m - VND 8.9m   \n",
       "3   20 - 29  20 - 24 y.o.  VND 4.5m - VND 8.9m   \n",
       "4   20 - 29  25 - 29 y.o.  VND 4.5m - VND 8.9m   \n",
       "\n",
       "                                          Occupation Occupation#group  Year  \\\n",
       "0  Unskilled Labor (worker, landry person, driver...      Blue Collar  2018   \n",
       "1  Unskilled Labor (worker, landry person, driver...      Blue Collar  2018   \n",
       "2  Unskilled Labor (worker, landry person, driver...      Blue Collar  2018   \n",
       "3  Skilled Labor (tailor, machinist, carpenter, e...      Blue Collar  2018   \n",
       "4  Semi-skilled labor (salesperson, waiter, photo...      Blue Collar  2018   \n",
       "\n",
       "   Col  \n",
       "0    3  \n",
       "1    3  \n",
       "2    3  \n",
       "3    3  \n",
       "4    3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##5 Dim_Customer\n",
    "df_dim_customer = df_sa.drop(columns=['MPI#2', 'MPI_Mean_Use'])\n",
    "df_dim_customer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f13627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Brand  Brand_ID BrandType\n",
      "0                                Highlands Coffee         1      None\n",
      "1                                 Indepedent Cafe         2      None\n",
      "2                                          Milano         3      None\n",
      "3                                        Gong Cha         4      None\n",
      "4                          Coffee Bean & Tea Leaf         5      None\n",
      "5                                       Phúc Long         6      None\n",
      "6                              The Coffee Factory         7      None\n",
      "7                                           Effoc         8      None\n",
      "8                                     Saigon Café         9      None\n",
      "9                                        KOI cafe        10      None\n",
      "10                                    Thức Coffee        11      None\n",
      "11                                         Passio        12      None\n",
      "12                               The Coffee House        13      None\n",
      "13                       Other Branded Cafe Chain        14      None\n",
      "14                                  Urban Station        15      None\n",
      "15                                    Maxx Coffee        16      None\n",
      "16                                      Starbucks        17      None\n",
      "17  Street / Half street coffee (including carts)        18      None\n",
      "18                                        Other 2        19      None\n",
      "19                                     Runam cafe        20      None\n",
      "20                                        Other 3        21      None\n",
      "21                                       Mộc Miên        22      None\n",
      "22                                       Nia cafe        23      None\n",
      "23                                         Đen Đá        24      None\n",
      "24                                       Aha Cafe        25      None\n",
      "25                                        Other 1        26      None\n",
      "26                                         Street        27      None\n",
      "27                                      Viva Star        28      None\n",
      "28                                    Laha Coffee        29      None\n",
      "29                                  Cheese Coffee        30      None\n",
      "30                                The Cups Coffee        31      None\n",
      "31                                         BonPas        32      None\n",
      "32                                      Long Cafe        33      None\n",
      "33                                       Mê Trang        34      None\n",
      "34                                          Other        35      None\n",
      "35                                   Trung Nguyên        36      None\n",
      "36                                    Cộng Cà Phê        37      None\n"
     ]
    }
   ],
   "source": [
    "##6 Dim_Brand\n",
    "df_dim_brand = df_BI[['Awareness']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_dim_brand['Brand_ID'] = range(1, len(df_dim_brand) + 1)\n",
    "df_dim_brand['BrandType'] = None\n",
    "df_dim_brand.rename(columns={'Awareness': 'Brand'}, inplace=True)\n",
    "print(df_dim_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e49cfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Needstate  \\\n",
      "0                                     Drinking coffee   \n",
      "1   Drinking other beverages (excluding tea, coffe...   \n",
      "2                                        Drinking tea   \n",
      "3                                Drinking ice-blended   \n",
      "4                         Socializing with colleagues   \n",
      "5                 Socializing with family / relatives   \n",
      "6                                          Socialzing   \n",
      "7                            Socializing with friends   \n",
      "8   Enterntainment (watching movies. Playing games...   \n",
      "9                                    Relaxing (Alone)   \n",
      "10            Have meals (breakfast / lunch / dinner)   \n",
      "11                                Have snack / pastry   \n",
      "12                           Studying / Reading books   \n",
      "13                                              Other   \n",
      "14                         Working / Business meeting   \n",
      "\n",
      "                NeedstateGroup  Needstate_ID  \n",
      "0           Drinking beverages             1  \n",
      "1           Drinking beverages             2  \n",
      "2           Drinking beverages             3  \n",
      "3           Drinking beverages             4  \n",
      "4                  Socializing             5  \n",
      "5                  Socializing             6  \n",
      "6                  Socializing             7  \n",
      "7                  Socializing             8  \n",
      "8     Relaxing & entertainment             9  \n",
      "9     Relaxing & entertainment            10  \n",
      "10               Meals & Snack            11  \n",
      "11               Meals & Snack            12  \n",
      "12           Studying & Others            13  \n",
      "13           Studying & Others            14  \n",
      "14  Working & business meeting            15  \n"
     ]
    }
   ],
   "source": [
    "##7 Dim_Needstate\n",
    "df_dim_needstate = df_ns[['Needstates', 'NeedstateGroup']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_dim_needstate['Needstate_ID'] = range(1, len(df_dim_needstate) + 1)\n",
    "df_dim_needstate.rename(columns={'Needstates': 'Needstate'}, inplace=True)\n",
    "print(df_dim_needstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec56f1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Companion#group  Companion_ID\n",
      "0                        Friends             1\n",
      "1                         Family             2\n",
      "2  Colleagues / Business partner             3\n",
      "3                          Alone             4\n",
      "4         Boyfriend / Girlfriend             5\n",
      "5                         Others             6\n"
     ]
    }
   ],
   "source": [
    "##8 Dim_Companion\n",
    "df_dim_companion = df_cp[['Companion#group']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_dim_companion['Companion_ID'] = range(1, len(df_dim_companion) + 1)\n",
    "print(df_dim_companion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21df4fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NPS#P3M NPS#P3M#Group  NPS_ID\n",
      "0       9.0      Promoter       1\n",
      "1       8.0       Passive       2\n",
      "2       7.0       Passive       3\n",
      "3      10.0      Promoter       4\n",
      "4       5.0     Detractor       5\n",
      "5       6.0     Detractor       6\n",
      "6       0.0     Detractor       7\n",
      "7       4.0     Detractor       8\n",
      "8       3.0     Detractor       9\n",
      "9       1.0     Detractor      10\n",
      "10      2.0     Detractor      11\n"
     ]
    }
   ],
   "source": [
    "##9 Dim_NPS\n",
    "df_dim_nps = df_BH[['NPS#P3M', 'NPS#P3M#Group']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_dim_nps['NPS_ID'] = range(1, len(df_dim_nps) + 1)\n",
    "print(df_dim_nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c305f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Segmentation  Segmentation_ID\n",
      "0               Seg.01 - Mass (<VND 25K)                1\n",
      "1  Seg.02 - Mass Asp (VND 25K - VND 59K)                2\n",
      "2   Seg.03 - Premium (VND 60K - VND 99K)                3\n",
      "3     Seg.04 - Super Premium (VND 100K+)                4\n"
     ]
    }
   ],
   "source": [
    "##10 Dim_Segmentation\n",
    "df_dim_segmentation = df_BH[['Segmentation']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "df_dim_segmentation['Segmentation_ID'] = range(1, len(df_dim_segmentation) + 1)\n",
    "print(df_dim_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e6c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID  Year    City         Awareness      Attribute        BrandImage  \\\n",
      "0  725118  2019  Hà Nội  Highlands Coffee  Popular brand  Highlands Coffee   \n",
      "1  725466  2019  Hà Nội  Highlands Coffee  Popular brand  Highlands Coffee   \n",
      "2  726561  2019  Hà Nội  Highlands Coffee  Popular brand  Highlands Coffee   \n",
      "3  726862  2019  Hà Nội  Highlands Coffee  Popular brand  Highlands Coffee   \n",
      "4  727219  2019  Hà Nội  Highlands Coffee  Popular brand  Highlands Coffee   \n",
      "\n",
      "   BI_ID  \n",
      "0      1  \n",
      "1      2  \n",
      "2      3  \n",
      "3      4  \n",
      "4      5  \n",
      "       ID  Year    City         Awareness      Attribute        BrandImage  \\\n",
      "0  725118  2019  Hà Nội  Highlands Coffee  Popular brand  Highlands Coffee   \n",
      "1  725466  2019  Hà Nội  Highlands Coffee  Popular brand  Highlands Coffee   \n",
      "2  726561  2019  Hà Nội  Highlands Coffee  Popular brand  Highlands Coffee   \n",
      "3  726862  2019  Hà Nội  Highlands Coffee  Popular brand  Highlands Coffee   \n",
      "4  727219  2019  Hà Nội  Highlands Coffee  Popular brand  Highlands Coffee   \n",
      "\n",
      "   BI_ID             Brand  Brand_ID  \n",
      "0      1  Highlands Coffee       1.0  \n",
      "1      2  Highlands Coffee       1.0  \n",
      "2      3  Highlands Coffee       1.0  \n",
      "3      4  Highlands Coffee       1.0  \n",
      "4      5  Highlands Coffee       1.0  \n",
      "       ID  Year    City      Attribute        BrandImage  BI_ID  Awareness_ID  \\\n",
      "0  725118  2019  Hà Nội  Popular brand  Highlands Coffee      1           1.0   \n",
      "1  725466  2019  Hà Nội  Popular brand  Highlands Coffee      2           1.0   \n",
      "2  726561  2019  Hà Nội  Popular brand  Highlands Coffee      3           1.0   \n",
      "3  726862  2019  Hà Nội  Popular brand  Highlands Coffee      4           1.0   \n",
      "4  727219  2019  Hà Nội  Popular brand  Highlands Coffee      5           1.0   \n",
      "\n",
      "              Brand  Brand_ID  \n",
      "0  Highlands Coffee         1  \n",
      "1  Highlands Coffee         1  \n",
      "2  Highlands Coffee         1  \n",
      "3  Highlands Coffee         1  \n",
      "4  Highlands Coffee         1  \n",
      "       ID  Year    City      Attribute  BI_ID  Awareness_ID  BrandImage_ID  \\\n",
      "0  725118  2019  Hà Nội  Popular brand      1           1.0              1   \n",
      "1  725466  2019  Hà Nội  Popular brand      2           1.0              1   \n",
      "2  726561  2019  Hà Nội  Popular brand      3           1.0              1   \n",
      "3  726862  2019  Hà Nội  Popular brand      4           1.0              1   \n",
      "4  727219  2019  Hà Nội  Popular brand      5           1.0              1   \n",
      "\n",
      "   City_ID  \n",
      "0        2  \n",
      "1        2  \n",
      "2        2  \n",
      "3        2  \n",
      "4        2  \n"
     ]
    }
   ],
   "source": [
    "##1 Fact_BrandImage\n",
    "df_fact_brand_image = df_BI\n",
    "df_fact_brand_image['BI_ID'] = range(1, len(df_fact_brand_image) + 1)\n",
    "print(df_fact_brand_image.head())\n",
    "\n",
    "#Merge Dim_Brand with Fact_BrandImage\n",
    "df_fact_brand_image = pd.merge(df_fact_brand_image, df_dim_brand[['Brand', 'Brand_ID']], left_on='Awareness', right_on='Brand', how='left')\n",
    "print(df_fact_brand_image.head())\n",
    "df_fact_brand_image.drop(columns=['Awareness', 'Brand'], inplace=True)\n",
    "df_fact_brand_image.rename(columns={'Brand_ID': 'Awareness_ID'}, inplace=True)\n",
    "\n",
    "df_fact_brand_image = pd.merge(df_fact_brand_image, df_dim_brand[['Brand', 'Brand_ID']], left_on='BrandImage', right_on='Brand', how='left')\n",
    "print(df_fact_brand_image.head())\n",
    "df_fact_brand_image.drop(columns=['BrandImage', 'Brand'], inplace=True)\n",
    "df_fact_brand_image.rename(columns={'Brand_ID': 'BrandImage_ID'}, inplace=True)\n",
    "\n",
    "# Merge Dim_City with Fact_BrandImage\n",
    "df_fact_brand_image = df_fact_brand_image.merge(df_dim_city[['City_ID', 'City']], on='City', how='left')\n",
    "print(df_fact_brand_image.head())\n",
    "df_fact_brand_image.drop(columns=['City'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44be2a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID  Year         City      Brand Spontaneous  Awareness Trial  P3M  \\\n",
      "0  345853  2018  Hồ Chí Minh  Phúc Long         NaN  Phúc Long   NaN  NaN   \n",
      "1  348403  2018  Hồ Chí Minh  Phúc Long         NaN  Phúc Long   NaN  NaN   \n",
      "2  349552  2018  Hồ Chí Minh  Phúc Long         NaN  Phúc Long   NaN  NaN   \n",
      "3  349764  2018  Hồ Chí Minh  Phúc Long         NaN  Phúc Long   NaN  NaN   \n",
      "4  350072  2018  Hồ Chí Minh  Phúc Long         NaN  Phúc Long   NaN  NaN   \n",
      "\n",
      "   P1M Comprehension Brand_Likability Weekly Daily  Fre#visit  PPA  Spending  \\\n",
      "0  NaN           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "1  NaN           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "2  NaN           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "3  NaN           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "4  NaN           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "\n",
      "  Segmentation  NPS#P3M  BH_ID  \n",
      "0          NaN      NaN      1  \n",
      "1          NaN      NaN      2  \n",
      "2          NaN      NaN      3  \n",
      "3          NaN      NaN      4  \n",
      "4          NaN      NaN      5  \n",
      "       ID  Year         City      Brand Spontaneous  Awareness Trial  P3M  \\\n",
      "0  345853  2018  Hồ Chí Minh  Phúc Long         NaN  Phúc Long   NaN  NaN   \n",
      "1  348403  2018  Hồ Chí Minh  Phúc Long         NaN  Phúc Long   NaN  NaN   \n",
      "2  349552  2018  Hồ Chí Minh  Phúc Long         NaN  Phúc Long   NaN  NaN   \n",
      "3  349764  2018  Hồ Chí Minh  Phúc Long         NaN  Phúc Long   NaN  NaN   \n",
      "4  350072  2018  Hồ Chí Minh  Phúc Long         NaN  Phúc Long   NaN  NaN   \n",
      "\n",
      "   P1M Comprehension Brand_Likability Weekly Daily  Fre#visit  PPA  Spending  \\\n",
      "0  NaN           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "1  NaN           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "2  NaN           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "3  NaN           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "4  NaN           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "\n",
      "  Segmentation  NPS#P3M  BH_ID  Brand_ID  \n",
      "0          NaN      NaN      1         6  \n",
      "1          NaN      NaN      2         6  \n",
      "2          NaN      NaN      3         6  \n",
      "3          NaN      NaN      4         6  \n",
      "4          NaN      NaN      5         6  \n",
      "       ID  Year         City Spontaneous  Awareness Trial  P3M  P1M  \\\n",
      "0  345853  2018  Hồ Chí Minh         NaN  Phúc Long   NaN  NaN  NaN   \n",
      "1  348403  2018  Hồ Chí Minh         NaN  Phúc Long   NaN  NaN  NaN   \n",
      "2  349552  2018  Hồ Chí Minh         NaN  Phúc Long   NaN  NaN  NaN   \n",
      "3  349764  2018  Hồ Chí Minh         NaN  Phúc Long   NaN  NaN  NaN   \n",
      "4  350072  2018  Hồ Chí Minh         NaN  Phúc Long   NaN  NaN  NaN   \n",
      "\n",
      "  Comprehension Brand_Likability Weekly Daily  Fre#visit  PPA  Spending  \\\n",
      "0           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "1           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "2           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "3           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "4           NaN              NaN    NaN   NaN        NaN  NaN       NaN   \n",
      "\n",
      "  Segmentation  NPS#P3M  BH_ID  Brand_ID  City_ID  \n",
      "0          NaN      NaN      1         6        3  \n",
      "1          NaN      NaN      2         6        3  \n",
      "2          NaN      NaN      3         6        3  \n",
      "3          NaN      NaN      4         6        3  \n",
      "4          NaN      NaN      5         6        3  \n",
      "       ID  Year Spontaneous  Awareness Trial  P3M  P1M Comprehension  \\\n",
      "0  345853  2018         NaN  Phúc Long   NaN  NaN  NaN           NaN   \n",
      "1  348403  2018         NaN  Phúc Long   NaN  NaN  NaN           NaN   \n",
      "2  349552  2018         NaN  Phúc Long   NaN  NaN  NaN           NaN   \n",
      "3  349764  2018         NaN  Phúc Long   NaN  NaN  NaN           NaN   \n",
      "4  350072  2018         NaN  Phúc Long   NaN  NaN  NaN           NaN   \n",
      "\n",
      "  Brand_Likability Weekly Daily  Fre#visit  PPA  Spending Segmentation  \\\n",
      "0              NaN    NaN   NaN        NaN  NaN       NaN          NaN   \n",
      "1              NaN    NaN   NaN        NaN  NaN       NaN          NaN   \n",
      "2              NaN    NaN   NaN        NaN  NaN       NaN          NaN   \n",
      "3              NaN    NaN   NaN        NaN  NaN       NaN          NaN   \n",
      "4              NaN    NaN   NaN        NaN  NaN       NaN          NaN   \n",
      "\n",
      "   NPS#P3M  BH_ID  Brand_ID  City_ID  Segmentation_ID  \n",
      "0      NaN      1         6        3              NaN  \n",
      "1      NaN      2         6        3              NaN  \n",
      "2      NaN      3         6        3              NaN  \n",
      "3      NaN      4         6        3              NaN  \n",
      "4      NaN      5         6        3              NaN  \n"
     ]
    }
   ],
   "source": [
    "##2 Fact_BrandHealth\n",
    "df_brand_health = df_BH.drop(columns=['Spending_use', 'NPS#P3M#Group'])\n",
    "df_brand_health['BH_ID'] = range(1, len(df_brand_health) + 1)\n",
    "print(df_brand_health.head())\n",
    "\n",
    "#Merge Dim_Brand with Fact_BrandHealth\n",
    "df_brand_health = df_brand_health.merge(df_dim_brand[['Brand_ID', 'Brand']], on='Brand', how='left')\n",
    "print(df_brand_health.head())\n",
    "df_brand_health.drop(columns=['Brand'], inplace=True)\n",
    "\n",
    "#Merge Dim_City with Fact_BrandHealth\n",
    "df_brand_health = df_brand_health.merge(df_dim_city[['City_ID', 'City']], on='City', how='left')\n",
    "print(df_brand_health.head())\n",
    "df_brand_health.drop(columns=['City'], inplace=True)\n",
    "\n",
    "# Merge Dim_Segmentation with Fact_BrandHealth\n",
    "df_brand_health = df_brand_health.merge(df_dim_segmentation[['Segmentation_ID', 'Segmentation']], on='Segmentation', how='left')\n",
    "print(df_brand_health.head())\n",
    "df_brand_health.drop(columns=['Segmentation'], inplace=True)\n",
    "\n",
    "# Merge Dim_NPS with Fact_BrandHealth\n",
    "df_brand_health = df_brand_health.merge(df_dim_nps[['NPS_ID', 'NPS#P3M']], on='NPS#P3M', how='left')\n",
    "print(df_brand_health.head())\n",
    "df_brand_health.drop(columns=['NPS#P3M'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0233a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID Companion#group  Fact_Companion_ID\n",
      "0  725466         Friends                  1\n",
      "1  726862         Friends                  2\n",
      "2  727015         Friends                  3\n",
      "3  727219         Friends                  4\n",
      "4  727611         Friends                  5\n",
      "       ID Companion#group  Fact_Companion_ID  Companion_ID\n",
      "0  725466         Friends                  1             1\n",
      "1  726862         Friends                  2             1\n",
      "2  727015         Friends                  3             1\n",
      "3  727219         Friends                  4             1\n",
      "4  727611         Friends                  5             1\n"
     ]
    }
   ],
   "source": [
    "##3 Fact_Companion\n",
    "df_fact_companion = df_cp.drop(columns=['Year', 'City'])\n",
    "df_fact_companion['Fact_Companion_ID'] = range(1, len(df_fact_companion) + 1)\n",
    "print(df_fact_companion.head())\n",
    "\n",
    "# Merge Dim_Companion with Fact_Companion\n",
    "df_fact_companion = df_fact_companion.merge(df_dim_companion, on='Companion#group', how='left')\n",
    "print(df_fact_companion.head())\n",
    "df_fact_companion.drop(columns=['Companion#group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90bca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID        Needstate  Fact_Needstate_ID\n",
      "0  725118  Drinking coffee                  1\n",
      "1  725466  Drinking coffee                  2\n",
      "2  726561  Drinking coffee                  3\n",
      "3  726862  Drinking coffee                  4\n",
      "4  727015  Drinking coffee                  5\n",
      "       ID        Needstate  Fact_Needstate_ID  Needstate_ID\n",
      "0  725118  Drinking coffee                  1             1\n",
      "1  725466  Drinking coffee                  2             1\n",
      "2  726561  Drinking coffee                  3             1\n",
      "3  726862  Drinking coffee                  4             1\n",
      "4  727015  Drinking coffee                  5             1\n"
     ]
    }
   ],
   "source": [
    "##4 Fact_Needstate (overall)\n",
    "df_fact_needstate = df_ns[df_ns['Day#Daypart'] == 'Overall'].drop(columns=['Day#Daypart', 'NeedstateGroup', 'Year', 'City'])\n",
    "df_fact_needstate['Fact_Needstate_ID'] = range(1, len(df_fact_needstate) + 1)\n",
    "df_fact_needstate.rename(columns={'Needstates': 'Needstate'}, inplace=True)\n",
    "print(df_fact_needstate.head())\n",
    "\n",
    "# Merging Dim_Needstate with Fact_Needstate\n",
    "df_fact_needstate = df_fact_needstate.merge(\n",
    "    df_dim_needstate[['Needstate', 'Needstate_ID']],\n",
    "    on='Needstate',\n",
    "    how='left'\n",
    ")\n",
    "print(df_fact_needstate.head())\n",
    "df_fact_needstate = df_fact_needstate.drop(columns=['Needstate'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c6d3d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No#        Brand        City  Year  StoreCount  StoreCount_ID\n",
      "0    6  Cộng Cà Phê   Hải Phòng  2017           1              1\n",
      "1    9  Cộng Cà Phê     Lào Cai  2017           1              2\n",
      "2   10  Cộng Cà Phê   Nha Trang  2017           1              3\n",
      "3   11  Cộng Cà Phê   Quảng Nam  2017           1              4\n",
      "4   12  Cộng Cà Phê  Quảng Ninh  2017           1              5\n",
      "   No#        Brand        City  Year  StoreCount  StoreCount_ID  City_ID\n",
      "0    6  Cộng Cà Phê   Hải Phòng  2017           1              1        5\n",
      "1    9  Cộng Cà Phê     Lào Cai  2017           1              2        7\n",
      "2   10  Cộng Cà Phê   Nha Trang  2017           1              3        6\n",
      "3   11  Cộng Cà Phê   Quảng Nam  2017           1              4        8\n",
      "4   12  Cộng Cà Phê  Quảng Ninh  2017           1              5        9\n",
      "   No#        Brand  Year  StoreCount  StoreCount_ID  City_ID  Brand_ID\n",
      "0    6  Cộng Cà Phê  2017           1              1        5        37\n",
      "1    9  Cộng Cà Phê  2017           1              2        7        37\n",
      "2   10  Cộng Cà Phê  2017           1              3        6        37\n",
      "3   11  Cộng Cà Phê  2017           1              4        8        37\n",
      "4   12  Cộng Cà Phê  2017           1              5        9        37\n"
     ]
    }
   ],
   "source": [
    "##5 Fact_StoreCount\n",
    "df_fact_store_count = df_count\n",
    "print(df_fact_store_count.head())\n",
    "\n",
    "# Merging Dim_City with Fact_StoreCount\n",
    "df_fact_store_count = df_fact_store_count.merge(\n",
    "    df_dim_city[['City', 'City_ID']],\n",
    "    on='City',\n",
    "    how='left'\n",
    ")\n",
    "print(df_fact_store_count.head())\n",
    "df_fact_store_count = df_fact_store_count.drop(columns=['City'])\n",
    "\n",
    "# Merging Dim_Brand with Fact_StoreCount\n",
    "df_fact_store_count = df_fact_store_count.merge(\n",
    "    df_dim_brand[['Brand', 'Brand_ID']],\n",
    "    on='Brand',\n",
    "    how='left'\n",
    ")\n",
    "print(df_fact_store_count.head())\n",
    "df_fact_store_count = df_fact_store_count.drop(columns=['Brand'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3074e2f",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ecc6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_brand_image.to_csv('Data/Fact_BrandImage.csv', sep=';', index=False)\n",
    "df_brand_health.to_csv('Data/Fact_BrandHealth.csv', sep=';', index=False)\n",
    "df_fact_companion.to_csv('Data/Fact_Companion.csv', sep=';', index=False)\n",
    "df_fact_needstate.to_csv('Data/Fact_Needstate.csv', sep=';', index=False)\n",
    "df_fact_store_count.to_csv('Data/Fact_StoreCount.csv', sep=';', index=False)\n",
    "df_dim_dow.to_csv('Data/Dim_Dayofweek.csv', sep=';', index=False)\n",
    "df_dim_daypart.to_csv('Data/Dim_Daypart.csv', sep=';', index=False)\n",
    "df_dim_year.to_csv('Data/Dim_Year.csv', sep=';', index=False)\n",
    "df_dim_city.to_csv('Data/Dim_City.csv', sep=';', index=False)\n",
    "df_dim_customer.to_csv('Data/Dim_Customer.csv', sep=';', index=False)\n",
    "df_dim_brand.to_csv('Data/Dim_Brand.csv', sep=';', index=False)\n",
    "df_dim_needstate.to_csv('Data/Dim_Needstate.csv', sep=';', index=False)\n",
    "df_dim_companion.to_csv('Data/Dim_Companion.csv', sep=';', index=False)\n",
    "df_dim_nps.to_csv('Data/Dim_NPS.csv', sep=';', index=False)\n",
    "df_dim_segmentation.to_csv('Data/Dim_Segmentation.csv', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
